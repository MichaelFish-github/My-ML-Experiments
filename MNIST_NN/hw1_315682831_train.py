# -*- coding: utf-8 -*-
"""ml2_wet_q2_hw1_315682831_train.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1hoxp7O3Zh9plfW98-Q3bnjZLdAK_CBMA
"""

import torch
import pickle
from torchvision import datasets, transforms
import matplotlib.pyplot as plt
from scipy.stats import bernoulli
import torch.nn as nn
import numpy as np


class Neural_Network(nn.Module):
    def __init__(self, input_size, hidden_size, num_classes):
        super(Neural_Network, self).__init__()
        self.layer1 = nn.Linear(input_size, hidden_size)
        self.activation1 = nn.ReLU()
        self.layer2 = nn.Linear(hidden_size, num_classes)

    def forward(self, X):
        out = self.layer1(X)
        out = self.activation1(out)
        out = self.layer2(out)
        return out


def load_create_random_labled_data():
    batch_size = 128
    transform = transforms.Compose([transforms.ToTensor()])
    train_set = datasets.MNIST('/files/', train=True, transform=transform, download=True)
    train_loader = torch.utils.data.DataLoader(dataset=train_set, batch_size=batch_size, shuffle=False)
    _, train_data = next(enumerate(train_loader))
    train_data = train_data[0]
    train_labels = torch.Tensor(bernoulli.rvs(0.5, size=batch_size)).long()

    test_set = datasets.MNIST('/files/', train=False, transform=transform, download=True)
    test_loader = torch.utils.data.DataLoader(dataset=test_set, batch_size=test_set.__len__(), shuffle=False)
    _, test_data = next(enumerate(test_loader))
    test_data = test_data[0]
    test_labels = torch.Tensor(bernoulli.rvs(0.5, size=test_set.__len__())).long()
    print(train_data.view(-1, 784).size())
    print(test_data.view(-1, 784).size())
    print(train_labels.size())
    print(test_labels.size())
    return train_data.view(-1, 784), train_labels, test_data.view(-1, 784), test_labels


def wet_q2_train(hidden_layer=90, learning_rate=0.2, num_epochs=1000):
    my_NN = Neural_Network(784, hidden_layer, 2)
    train_data, train_labels, test_data, test_labels = load_create_random_labled_data()

    if torch.cuda.is_available():
        my_NN = my_NN.cuda()

    criterion = nn.CrossEntropyLoss()
    optimizer = torch.optim.SGD(my_NN.parameters(), lr=learning_rate)

    train_acc_list = []
    test_acc_list = []
    train_loss_list = []
    test_loss_list = []

    for epoch in range(num_epochs):
        if torch.cuda.is_available():
            train_data = train_data.cuda()
            train_labels = train_labels.cuda()

        # train phase
        train_output = my_NN(train_data)
        train_loss = criterion(train_output, train_labels)
        optimizer.zero_grad()
        train_loss.backward()
        optimizer.step()
        train_prediction = torch.max(train_output.data, 1)[1]
        train_acc = torch.sum(train_prediction == train_labels).item()
        train_acc = train_acc / train_prediction.shape[0]
        train_acc_list.append(train_acc)
        train_loss_list.append(train_loss.item())

        if torch.cuda.is_available():
            test_data = test_data.cuda()
            test_labels = test_labels.cuda()

        # test phase
        test_output = my_NN(test_data)
        test_loss = criterion(test_output, test_labels)
        test_prediction = torch.max(test_output.data, 1)[1]
        test_acc = torch.sum(test_prediction == test_labels).item()
        test_acc = test_acc / test_prediction.shape[0]
        test_acc_list.append(test_acc)
        test_loss_list.append(test_loss.item())

        # # Lost and accuracy prints
        # print(f"epoch number: {epoch}")
        # print("")
        # print(f"train accuracy: {train_acc}")
        # print(f"train loss: {train_loss.item()}")
        # print(f"test accuracy: {test_acc}")
        # print(f"test loss: {test_loss.item()}")
        # print("----------------------------------------------------------------------------")

    with open("wet_weights_q2_315682831.pkl", "wb") as f:
        pickle.dump((my_NN, train_data, train_labels), f)
    return train_acc_list, test_acc_list, train_loss_list, test_loss_list


def plot_acc_loss(train_acc_list, test_acc_list, train_loss_list, test_loss_list):
    x_axis = np.arange(1, 1001)

    # Accuracy plot
    plt.plot(x_axis, train_acc_list, label="train accuracy")
    plt.plot(x_axis, test_acc_list, label="test accuracy")
    plt.xlabel("Epoch number")
    plt.ylabel("Accuracy")
    plt.title("Accuracy per epoc")
    plt.legend(loc='upper right')
    plt.show()

    print()

    # Loss plot
    plt.plot(x_axis, train_loss_list, label="train loss")
    plt.plot(x_axis, test_loss_list, label="test loss")
    plt.xlabel("Epoch number")
    plt.ylabel("Loss")
    plt.title("Loss per epoc")
    plt.legend(loc='upper right')
    plt.show()


train_acc_list, test_acc_list, train_loss_list, test_loss_list = wet_q2_train()
plot_acc_loss(train_acc_list, test_acc_list, train_loss_list, test_loss_list)
print("")
print(f"Mean loss on the test set is: {np.mean(test_loss_list)}")
print(f"Mean accuracy on the test set is: {np.mean(test_acc_list)}")

